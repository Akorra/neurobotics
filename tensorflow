# Copyright 2015 Google Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

"""Trains and Evaluates the MNIST network using a feed dictionary."""
# pylint: disable=missing-docstring
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import time

from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf
import numpy as np




# Basic model parameters as external flags.
flags = tf.app.flags
FLAGS = flags.FLAGS
flags.DEFINE_float('learning_rate_critic', 0.01, 'Initial learning rate.')
flags.DEFINE_float('learning_rate_actor', 0.01, 'Initial learning rate.')
flags.DEFINE_float('tau_moving_avrg',0.99, 'Parameter to update old networks')
flags.DEFINE_float('gamma_reward_discount',0.9,
                'Parameter determines how much future rewards are discounted')

flags.DEFINE_integer('max_steps', 2000, 'Number of steps to run trainer.')

flags.DEFINE_integer('image_size', 84, 'Image width')
flags.DEFINE_integer('fully1', 200, 'Number of units in hidden layer 1.')
flags.DEFINE_integer('fully2', 200, 'Number of units in hidden layer 2.')
flags.DEFINE_integer('receptive_field1', 8,
                    'Receiptive field for Convolutional layer 1.')
flags.DEFINE_integer('receptive_field2', 4,
                    'Receiptive field for Convolutional layer 2.')
flags.DEFINE_integer('receptive_field3', 3,
                    'Receiptive field for Convolutional layer 3.')
flags.DEFINE_integer('stride1', 4, 'Stride for Convolutional layer 1.')
flags.DEFINE_integer('stride2', 2, 'Stride for Convolutional layer 2.')
flags.DEFINE_integer('stride3', 1, 'Stride for Convolutional layer 3.')

flags.DEFINE_integer('batch_size', 100, 'Batch size.  '
                     'Must divide evenly into the dataset sizes.')
flags.DEFINE_string('train_dir', 'data', 'Directory to put the training data.')
flags.DEFINE_boolean('fake_data', False, 'If true, uses fake data '
                     'for unit testing.')



def build_Q(raw_image, actions, image_size, fully1_units, fully2_units,
            receiptive_field1, receiptive_field2, receiptive_field3,
            stride1, stride2, stride3):
  """Build the network model up to where it may be used for inference."""
  # reshape image to apply convolution
  reshaped_image = tf.reshape(raw_image, [-1,image_size,image_size,1])

  # Conv 1
  with tf.variable_scope('Q'):
    fan_in = receiptive_field1*receiptive_field1
    weights_conv1=tf.get_variable(
                shape=[receiptive_field1, receiptive_field1, 1, 32],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='weights_conv1')
    biases_conv1=tf.get_variable(shape=[32],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='biases_conv1')
    conv1 = tf.nn.relu(tf.nn.conv2d(reshaped_image, weights_conv1,
                strides=[1, stride1, stride1, 1], padding='VALID')
                # padding=valid means no padding
	            + biases_conv1)

    # Conv 2
    fan_in = receiptive_field2*receiptive_field2*32
    weights_conv2=tf.get_variable(
                shape=[receiptive_field2, receiptive_field2, 32, 32],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='weights_conv2')
    biases_conv2 =tf.get_variable(shape=[32],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='biases_conv2')
    conv2 = tf.nn.relu(tf.nn.conv2d(conv1, weights_conv2,
                strides=[1, stride2, stride2, 1], padding='VALID')
	            + biases_conv2)

    # Conv 3
    fan_in = receiptive_field3*receiptive_field3*32
    weights_conv3=tf.get_variable(
                shape=[receiptive_field3, receiptive_field3, 32, 32],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='weights_conv3')
    biases_conv3 =tf.get_variable(shape=[32],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='biases_conv3')
    conv3 = tf.nn.relu(tf.nn.conv2d(conv2, weights_conv3,
                strides=[1, stride3, stride3, 1], padding='VALID')
	            + biases_conv3)

    # this must be adjudted if the conv network architecture is changed:
    conv3_output = 7*7*32

    # reshape output tensor to a rank 1 tensor
    conv3_flat = tf.reshape(conv3, [-1, conv3_output])

    # Fully Connected Layer 1
    conv3_output = 7*7*32
    weights_fully1 =tf.get_variable(
                shape=[conv3_output, fully1_units],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='weights_fully1')
    weights_actions =tf.get_variable(
                shape=[2, fully1_units],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='weights_actions')
    biases_fully1 =tf.get_variable(shape=[fully1_units],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='biases_fully1')
    fully1 = tf.nn.relu(tf.matmul(conv3_flat, weights_fully1) +
                tf.matmul(actions,weights_actions) + biases_fully1)

    # Fully Connected Layer 2
    fan_in = fully1_units
    weights_fully2 =tf.get_variable(
                shape=[fully1_units, fully2_units],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='weights_fully2')
    biases_fully2 = tf.get_variable(shape=[fully2_units],
                initializer=tf.random_uniform_initializer(
                    minval=-1/np.sqrt(fan_in), maxval=1/np.sqrt(fan_in)),
                name='biases_fully2')
    fully2 = tf.nn.relu(tf.matmul(fully1, weights_fully2) + biases_fully2)

    # Linear Output
    fan_in = fully2_units
    weights_final =tf.get_variable(shape=[fully2_units, 1],
                initializer=tf.random_uniform_initializer(
                    minval=-0.0003, maxval=0.0003),
                name='weights_final')
    biases_final = tf.get_variable(shape=[1],
                initializer=tf.random_uniform_initializer(
                    minval=-0.0003, maxval=0.0003),name='biases_final')



    Q= tf.matmul(fully2, weights_final) + biases_final

    # export all the weights as a dictionary
    weights_collection = dict()
    weights_collection['weights_conv1'] = weights_conv1
    weights_collection['biases_conv1'] = biases_conv1
    weights_collection['weights_conv2'] = weights_conv2
    weights_collection['biases_conv2'] = biases_conv2
    weights_collection['weights_conv3'] = weights_conv3
    weights_collection['biases_conv3'] = biases_conv3
    weights_collection['weights_fully1'] = weights_fully1
    weights_collection['biases_fully1'] = biases_fully1
    weights_collection['weights_actions'] = weights_actions

    weights_collection['weights_fully2'] = weights_fully2
    weights_collection['biases_fully2'] = biases_fully2
    weights_collection['weights_final'] = weights_final
    weights_collection['biases_final'] = biases_final
  return (Q, weights_collection)

def build_Q_target(raw_image, actions, image_size,stride1, stride2, stride3,
                weights_coll_Q):
   """Build the network model up to where it may be used for inference."""
   # reshape image to apply convolution
   reshaped_image = tf.reshape(raw_image, [-1,image_size,image_size,1])

   # Conv 1
   with tf.variable_scope('Q_target'):
     weights_conv1=tf.Variable(weights_coll_Q['weights_conv1'].initialized_value())
     biases_conv1=tf.Variable(weights_coll_Q['biases_conv1'].initialized_value())
     conv1 = tf.nn.relu(tf.nn.conv2d(reshaped_image, weights_conv1, strides=[1, stride1, stride1, 1], padding='VALID')
 	 + biases_conv1)

     # Conv 2
     weights_conv2=tf.Variable(weights_coll_Q['weights_conv2'].initialized_value())
     biases_conv2 =tf.Variable(weights_coll_Q['biases_conv2'].initialized_value())
     conv2 = tf.nn.relu(tf.nn.conv2d(conv1, weights_conv2, strides=[1, stride2, stride2, 1], padding='VALID')
 	 + biases_conv2)

     # Conv 3
     weights_conv3=tf.Variable(weights_coll_Q['weights_conv3'].initialized_value())
     biases_conv3 =tf.Variable(weights_coll_Q['biases_conv3'].initialized_value())
     conv3 = tf.nn.relu(tf.nn.conv2d(conv2, weights_conv3, strides=[1, stride3, stride3, 1], padding='VALID')
	    + biases_conv2)

     # reshape output tensor to a rank 1 tensor
     conv3_flat = tf.reshape(conv3, [-1, 7*7*32])

     # Fully Connected Layer 1
     weights_fully1 =tf.Variable(weights_coll_Q['weights_fully1'].initialized_value())
     weights_actions =tf.Variable(weights_coll_Q['weights_actions'].initialized_value())
     biases_fully1 =tf.Variable(weights_coll_Q['biases_fully1'].initialized_value())
     fully1 = tf.nn.relu(tf.matmul(conv3_flat, weights_fully1) + tf.matmul(actions,weights_actions) + biases_fully1)

     # Fully Connected Layer 2
     weights_fully2 =tf.Variable(weights_coll_Q['weights_fully2'].initialized_value())
     biases_fully2 = tf.Variable(weights_coll_Q['biases_fully2'].initialized_value())
     fully2 = tf.nn.relu(tf.matmul(fully1, weights_fully2) + biases_fully2)

     # Linear Output
     weights_final =tf.Variable(weights_coll_Q['weights_final'].initialized_value())
     biases_final = tf.Variable(weights_coll_Q['biases_final'].initialized_value())
     Q_target= tf.matmul(fully2, weights_final) + biases_final

     # export all the weights as a dictionary
     weights_collection = dict()
     weights_collection['weights_conv1'] = weights_conv1
     weights_collection['biases_conv1'] = biases_conv1
     weights_collection['weights_conv2'] = weights_conv2
     weights_collection['biases_conv2'] = biases_conv2
     weights_collection['weights_conv3'] = weights_conv3
     weights_collection['biases_conv3'] = biases_conv3
     weights_collection['weights_fully1'] = weights_fully1
     weights_collection['biases_fully1'] = biases_fully1
     weights_collection['weights_actions'] = weights_actions
     weights_collection['weights_fully2'] = weights_fully2

     weights_collection['biases_fully2'] = biases_fully2
     weights_collection['weights_final'] = weights_final
     weights_collection['biases_final'] = biases_final
   return (Q_target, weights_collection)



def moving_avrg(dic_Q, dic_Q_target,tau,sess):
    for variable in dic_Q_target:
        start_time = time.time()
        avrg_val = tau*dic_Q[variable].eval(sess)+(1-tau)*
                        dic_Q_target[variable].eval(sess)

        assign_op = dic_Q_target[variable].assign(avrg_val)

        sess.run(assign_op)
        duration = time.time() - start_time

        print(variable)
        print(duration)


def run_training():
  # Next varaibles will later be fed from the replay buffer
  image = np.random.rand(84,84).astype('f')
  new_image = np.random.rand(84,84).astype('f')
  actions = np.random.rand(1,2).astype('f')
  new_actions = np.random.rand(1,2).astype('f') #calculated by actor
  reward = np.random.rand(1).astype('f')

  #data_sets = input_data.read_data_sets(FLAGS.train_dir, FLAGS.fake_data)

  # Tell TensorFlow that the model will be built into the default Graph.
  with tf.Graph().as_default() as g:
    # Generate placeholders for the images and labels.
    #images_placeholder, labels_placeholder = placeholder_inputs(
    #    FLAGS.batch_size)

    # Build the Q and the Q_target network.
    Q, dic_Q= build_Q(image, actions,
                            FLAGS.image_size,
			                FLAGS.fully1,
			                FLAGS.fully2,
			                FLAGS.receptive_field1,
			                FLAGS.receptive_field2,
                            FLAGS.receptive_field3,
                            FLAGS.stride1,
                            FLAGS.stride2,
                            FLAGS.stride3)
    Q_target, dic_Q_target= build_Q_target(new_image, new_actions,
                            FLAGS.image_size,
                            FLAGS.stride1,
                            FLAGS.stride2,
                            FLAGS.stride3,
			                dic_Q)



    # calculate td 1 error: Q(s,a)-(r(s,a)+gamma*Q(s',a'))S
    td_error = Q -(reward + FLAGS.gamma_reward_discount*Q_target)

    # Loss for Q net
    loss = tf.reduce_mean(tf.square(td_error))

    # create optimizer op
    optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate_critic)

    # Use the optimizer to apply the gradients that minimize the loss
    # (and also increment the global step counter) as a single training step.
    train_op = optimizer.minimize(loss)

    # Add the variable initializer Op.
    init = tf.initialize_all_variables()

    # Create a session for running Ops on the Graph.
    sess = tf.Session()

    # Run the Op to initialize the variables.
    sess.run(init)

    print('Q: %f',sess.run(Q))
    print('\n')

    start_time = time.time()
    # run a training step
    sess.run(train_op)
    duration = time.time() - start_time

    print(duration)

    print('Q: %f',sess.run(Q))
    print('\n')



    moving_avrg(dic_Q,dic_Q_target,0.5,sess)



    '''
    #print(weights_coll_QSS_target["biases_final"].eval(sess))
    print('Q_target: %f',sess.run(Q_target))
    print('\n')

    #assign_op = dic_Q_target['biases_fully1'].assign([1])
    #sess.run(assign_op)

    print('modified Q: %f',sess.run(Q))
    print('\n')

    moving_avrg(dic_Q,dic_Q_target,0.5,sess)

    print('mov avrg Q_target: %f',sess.run(Q_target))'''




def main(_):
  run_training()


if __name__ == '__main__':
  tf.app.run()
